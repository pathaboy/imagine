import { assemblyAIClient } from "@/lib/assemblyai"
import { cameraAngles, cameraFramingTechniques, imageStyles, motionTemplatesNames, shots } from "@/lib/data"
import { gemini } from "@/lib/gemini"
import axios from "axios"


const systemImagePrompt = `
 You will be given two inputs:
1. A full video script.
2. SRT subtitle content
Your task is to map each subtitle entry (based on its time range and text) to one unique image prompt that visually represents the scene during that time in the video.
ðŸ”§ Instructions:
Parse each subtitle block from the SRT.
For each subtitle, generate exactly one descriptive image prompt with shot type, framing technique and camera angle that reflects the subtitleâ€™s content, inferred tone, and relevant surrounding context from the full script.
Output should contain the same number of image prompts as subtitle entries. No merging or skipping.
Convert start and end times to milliseconds.
Respond with valid parsable JSON:
{
  "imagePrompts": [
    {
      "id": 1,
      "start": 1000(in ms),
      "end": 3000(in ms),
      "imagePrompt": "A dimly lit alleyway with a man hiding behind a dumpster, tension in the air, extreme-wide-shot high-angle",
      "shotSize": "extreme-wide-shot",
      "cameraAngle": "high-angle",
      "cameraMotion": "pull-out"
    },
    ...
  ]
}
âš ï¸ Important Constraints:
Do not include any written text, quotes, phrases, or words in the image prompt.
The visual should be purely scene-based: use settings, people, objects, mood, lighting, emotions, camera angle, shot type, framing technique.
Avoid describing text, signs, titles, or captions in the prompt.
Available shot types: ${shots.join(" | ")}
Available framing techniques: ${cameraFramingTechniques.join(" | ")}
Available camera angles: ${cameraAngles.join(" | ")}
Available camera motions: ${motionTemplatesNames.map(item => item.name).join(" | ")}
Select camera motions like a professional editor, avoiding the repetition of the same camera motion back-to-back.
ðŸŽ¯ Ensure:
One-to-one mapping between SRT entries and image prompts.
No imagePrompt contains literal quotes or any textual content.
Descriptive, vivid, cinematic, shot size, camera angle image prompts based on the scene.
All entries must be present in the output, no loss of data.
No repetition of the same camera motion back-to-back.
`

interface ImagePrompt {
  id: number
  start: number
  end: number
  imagePrompt: string
  shotSize: string
  cameraAngle: string
  cameraMotion: string
}

export const generateImagePrompts = async (transcriptionId: string, imageStyle: string) => {
  try {
    const transcript = await assemblyAIClient.transcripts.get(transcriptionId)
    const script = transcript.text
    if (!script) {
      throw new Error("Found empty script")
    }
    const srtfile = await assemblyAIClient.transcripts.subtitles(transcriptionId)

    const res = await gemini.models.generateContent({
      model: "gemini-2.0-flash",
      contents: `
        Script: ${script}
        SRT: ${srtfile}
      `,
      config: {
        systemInstruction: systemImagePrompt
      }
    })
    const text = res.text?.replace("```json", "").replace("```", "")
    const response = JSON.parse(text || "")

    const styleTags = imageStyles.find((item, _index) => {
            return item.name.toLowerCase() === imageStyle.toLowerCase()
          })
    const imagePrompts: ImagePrompt[] = response.imagePrompts
    const enhancedImagePrompts = imagePrompts.map((item) => {
      return (
        {
          ...item,
          imagePrompt: item.imagePrompt + styleTags?.tags
        }
      )
    })
    return ({
      imagePrompts: enhancedImagePrompts
    })
  } catch (err: any) {
    console.error(`Failed to generate image prompts: ${err.message || err}`)
    throw new Error(`Failed to generate image prompts: ${err.message || err}`)
  }
}